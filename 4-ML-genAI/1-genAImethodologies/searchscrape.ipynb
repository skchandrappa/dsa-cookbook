{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# #### Pre Installs\n",
        "# import os\n",
        "# os.environ['openAIAPIKey'] = ''\n",
        "# os.environ['serpAPIKey'] = ''\n",
        "!pip install google-search-results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhApqbbXAupk",
        "outputId": "1575afa0-8ac2-4f27-b5e9-9d20efe5a045"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.10/dist-packages (2.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "appConfig = {\n",
        "    \"NoOfLinks\" : 3,\n",
        "    \"oaSystemprompt\" : \"You are an assistant that analyzes the contents of a website and provides a short summary, ignoring text that might be navigation related. Respond in markdown.\",\n",
        "    \"oaUserprompt\" : \"\"\n",
        "}"
      ],
      "metadata": {
        "id": "3Jro5ntlS68W"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "class getApiKeys:\n",
        "\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def getApiKeys(self,apiKey):\n",
        "    return os.environ.get(apiKey)"
      ],
      "metadata": {
        "id": "OKQztJvr9_6h"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import serpapi\n",
        "import json\n",
        "from serpapi import GoogleSearch # Add this import statement\n",
        "\n",
        "class searchForLinks:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def getSearchResults(self,searchWord):\n",
        "    searpApiKey = getApiKeys()\n",
        "    params = {\n",
        "      \"q\": searchWord,\n",
        "      \"hl\": \"en\",\n",
        "      \"gl\": \"us\",\n",
        "      \"google_domain\": \"google.com\",\n",
        "      \"api_key\": searpApiKey.getApiKeys('serpAPIKey')\n",
        "    }\n",
        "\n",
        "    search = GoogleSearch(params)\n",
        "    results = search.get_dict()\n",
        "    linksList = []\n",
        "\n",
        "    if 'organic_results' in results:\n",
        "        for res in results['organic_results']:\n",
        "            if 'link' in res:  # Check if 'link' key exists in each result dictionary\n",
        "                linksList.append(res['link'])\n",
        "    else:\n",
        "        print(\"No organic results found in the response.\")\n",
        "\n",
        "    return linksList[:appConfig['NoOfLinks']]"
      ],
      "metadata": {
        "id": "B9I34FupATv7"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sfl = searchForLinks()\n",
        "sfl.getSearchResults('coffee')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBhuzSauPlr6",
        "outputId": "cae45c46-f176-4e4c-ed3f-39d1e7a19a8b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://en.wikipedia.org/wiki/Coffee',\n",
              " 'https://bluebottlecoffee.com/?srsltid=AfmBOoq8gnRau5HYxQYISjN2ayTy3oODuySShGu6HG4dXRIOxORDg1dQ',\n",
              " 'https://www.starbucks.com/']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "\n",
        "class webCrawler:\n",
        "\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def crawlresults(self,srch):\n",
        "    sfl = searchForLinks()\n",
        "    linktocrawl = sfl.getSearchResults(srch)\n",
        "    print(linktocrawl)\n",
        "    crawlJson = {}\n",
        "    for links in linktocrawl:\n",
        "      crawlJson.update(self.crawl(links))\n",
        "\n",
        "    return crawlJson\n",
        "\n",
        "  def crawl(self, url: str):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    title = soup.title.string if soup.title else \"Title not found\"\n",
        "\n",
        "    if soup.body:\n",
        "      for irrelevant in soup.body([\"script\", \"style\",\"img\",\"input\"]):\n",
        "        irrelevant.decompose()\n",
        "      text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
        "    else:\n",
        "      text = \"\"\n",
        "\n",
        "    return {title : text}\n",
        "\n",
        "    # links = [link.get('href') for link in soup.find_all('a')]\n",
        "    # self.links = [link for link in links if link]"
      ],
      "metadata": {
        "id": "nRr7KRn8AeY7"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "# from dotenv import load_dotenv\n",
        "from bs4 import BeautifulSoup\n",
        "from IPython.display import Markdown, display\n",
        "from openai import OpenAI\n",
        "import time\n",
        "\n",
        "\n",
        "class summarizer:\n",
        "\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def user_prompt_for(self,title,text):\n",
        "      user_prompt = f\"You are looking at a website titled {title}\"\n",
        "      user_prompt += \"The contents of this website is as follows; \\\n",
        "                      please provide a short summary of this website in markdown. \\\n",
        "                      If it includes news or announcements, then summarize these too.\\n\\n\"\n",
        "      user_prompt += text\n",
        "      return user_prompt\n",
        "\n",
        "  def messages_for(self,content):\n",
        "      return [\n",
        "          {\"role\": \"system\", \"content\": appConfig['oaSystemprompt']},\n",
        "          {\"role\": \"user\", \"content\": content}\n",
        "      ]\n",
        "\n",
        "  def summarize(self,url):\n",
        "      searpApiKey = getApiKeys()\n",
        "      openai = OpenAI(api_key=searpApiKey.getApiKeys('serpAPIKey'))\n",
        "\n",
        "      crawl = webCrawler()\n",
        "      contents = crawl.crawlresults('coffee')\n",
        "\n",
        "      for content in contents:\n",
        "        user_prompt = self.user_prompt_for(content,contents[content])\n",
        "        messages = self.messages_for(content)\n",
        "        print(user_prompt)\n",
        "      # try:\n",
        "      #   response = openai.chat.completions.create(\n",
        "      #       model = \"gpt-4o-mini\",\n",
        "      #       messages = messages_for(website)\n",
        "      #   )\n",
        "      #   return response.choices[0].message.content\n",
        "      # except openai.error.RateLimitError:\n",
        "      #   print(\"Rate limit exceeded. Waiting for 60 seconds...\")\n",
        "      #   time.sleep(60)  # Wait for 60 seconds before retrying\n",
        "      #   return summarize(url)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R2Zx1YHBUb86"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize(\"coffee\")\n",
        "extract = summarizer()\n",
        "extract.summarize('coffee')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "PKUO9wpKAkgK",
        "outputId": "692e864f-0379-4ffc-b63a-5b7c01046f87"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OpenAIError",
          "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-448b05efe8eb>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# summarize(\"coffee\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mextract\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mextract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'coffee'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-39-4602a9047b05>\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0msearpApiKey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetApiKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m       \u001b[0mopenai\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearpApiKey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetApiKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'serpAPIKey'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0mcrawl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebCrawler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             raise OpenAIError(\n\u001b[0m\u001b[1;32m    106\u001b[0m                 \u001b[0;34m\"The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             )\n",
            "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "86Ek2sxb7SwR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}